import torch
import torch.nn as nn
import torch.optim as optim
import os
import time
from tqdm import tqdm
import numpy as np
from torchvision import transforms, models
from torch.utils.data import DataLoader, Dataset
import json
from PIL import Image
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
import random
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
import pandas as pd
from functools import lru_cache
# DINO ëª¨ë¸ì„ ìœ„í•œ ì¶”ê°€ import
import torch.hub
# Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from rich.panel import Panel
from rich.layout import Layout
from rich.live import Live
from rich.text import Text
from rich import box

# Rich ì½˜ì†” ì´ˆê¸°í™”
console = Console()

# NT-Xent Contrastive Loss í•¨ìˆ˜ (ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ë§Œ ìœ ì§€)
def nt_xent_loss(features, labels, temperature=0.07):
    """NT-Xent contrastive learning loss for paired augmentations"""
    b, n, d = features.shape
    assert n == 2, "Contrastive loss requires paired augmentations"
    
    # Normalize features
    features = F.normalize(features, dim=2)
    
    # Concatenate features
    features_flat = features.view(b * n, d)
    
    # Similarity matrix
    similarity_matrix = torch.matmul(features_flat, features_flat.T) / temperature
    
    # Mask to remove self-similarity
    mask = torch.eye(b * n, device=features.device, dtype=torch.bool)
    similarity_matrix = similarity_matrix[~mask].view(b * n, -1)
    
    # Labels for loss
    labels_flat = torch.arange(b * n, device=features.device) // n
    labels_flat = labels_flat.contiguous().view(-1, 1)
    mask = torch.eq(labels_flat, labels_flat.T).float()
    mask = mask[~torch.eye(b * n, device=features.device, dtype=torch.bool)].view(b * n, -1)
    
    # Positive and negative similarities
    positives = similarity_matrix[mask.bool()].view(b * n, -1)
    negatives = similarity_matrix[~mask.bool()].view(b * n, -1)
    
    # Logits
    logits = torch.cat([positives, negatives], dim=1)
    
    # Ground truth labels
    labels = torch.zeros(b * n, dtype=torch.long, device=features.device)
    
    # Cross-entropy loss
    loss = F.cross_entropy(logits, labels)
    
    return loss

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
class AverageMeter:
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
    
    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

def accuracy(output, target, topk=(1,)):
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)
        
        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))
        
        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res

def save_checkpoint(model, optimizer, epoch, acc, filepath):
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'accuracy': acc,
    }, filepath)

# ì„¤ì • í´ë˜ìŠ¤ ì •ì˜
class Config:
    def __init__(self):
        # ê¸°ë³¸ ì„¤ì • - ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ìˆ˜ì •
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.num_classes = 3
        self.batch_size = 32  
        self.num_epochs = 20  # ì—í¬í¬ ê°ì†Œ
        self.learning_rate = 1e-4  # í•™ìŠµë¥ ì„ 1e-4ë¡œ ìˆ˜ì •
        self.weight_decay = 1e-4  # Weight decayë¥¼ 1e-4ë¡œ ìˆ˜ì •
        self.temperature = 0.07  # Temperatureë¥¼ 0.07ë¡œ ë‚®ì¶¤ (origin_train.pyì™€ ë™ì¼)
        
        # ëª¨ë¸ ì„¤ì • - ì¼ë°˜ ResNet50ìœ¼ë¡œ ë³€ê²½
        self.backbone_name = 'resnet50_pretrained'
        self.projection_dim = 128  # íŠ¹ì§• ì°¨ì›ì„ 256ìœ¼ë¡œ ìœ ì§€ (origin_train.pyì™€ ë™ì¼)
        self.image_size = 192  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 192ë¡œ ìˆ˜ì •
        
        # Validation ì„¤ì •
        self.val_batch_size = 32
        self.val_samples_per_class = 200
        
        # ê²½ë¡œ ì„¤ì •
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.dataset_dir = os.path.join(self.base_dir, 'datasets')
        self.save_dir = os.path.join(self.base_dir, 'output')
        self.log_dir = os.path.join(self.base_dir, 'logs')
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.save_dir, exist_ok=True)
        os.makedirs(self.log_dir, exist_ok=True)

# Projection Head í´ë˜ìŠ¤ - ë‹¨ìˆœí™”ëœ ë²„ì „ (Dropout ì œê±°)
class ProjectionHead(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.projection = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, output_dim)
        )
    
    def forward(self, x):
        return self.projection(x)

# Pretrained ResNet50 ê¸°ë°˜ ëª¨ë¸ í´ë˜ìŠ¤
class CatDiscriminationModel(nn.Module):
    def __init__(self, config):
        super(CatDiscriminationModel, self).__init__()
        
        # Pretrained ResNet50 ë°±ë³¸
        if config.backbone_name == 'resnet50_pretrained':
            # Pretrained ResNet50 ëª¨ë¸ ë¡œë“œ
            self.backbone = models.resnet50(pretrained=True)
            # ë§ˆì§€ë§‰ fully connected layer ì œê±°
            self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])
            backbone_dim = 2048  # ResNet50ì˜ íŠ¹ì§• ì°¨ì›
        else:
            raise ValueError(f"Unsupported backbone: {config.backbone_name}")
            
        # Projection head (ë‹¨ìˆœí™”ëœ ë²„ì „)
        self.projection_head = ProjectionHead(
            input_dim=backbone_dim,
            hidden_dim=512,
            output_dim=config.projection_dim
        )
        
        # ë¶„ë¥˜ í—¤ë“œ - ë‹¨ì¼ ì„ í˜• ë ˆì´ì–´ë¡œ ë‹¨ìˆœí™”
        self.classifier = nn.Linear(config.projection_dim, config.num_classes)
        
    def forward(self, x, return_features=False):
        # Pretrained ResNet50 ë°±ë³¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        features = self.backbone(x)
        features = features.view(features.size(0), -1)  # Flatten
        
        # Projection head
        projected_features = self.projection_head(features)
        
        # L2 ì •ê·œí™”
        projected_features = F.normalize(projected_features, dim=1)
        
        if return_features:
            return projected_features
        
        # ë¶„ë¥˜ - ë‹¨ì¼ ì„ í˜• ë ˆì´ì–´
        logits = self.classifier(projected_features)
        return logits, projected_features

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (Contrastive Learningìš©) - ìºì‹± ì œê±°ë¡œ ì´ˆê¸° ë¡œë”© ì†ë„ ê°œì„ 
class CatDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None, is_training=True):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        self.is_training = is_training
        
    def __len__(self):
        return len(self.image_paths)
    
    def _load_image(self, image_path):
        return Image.open(image_path).convert('RGB')
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        label = self.labels[idx]
        
        image = self._load_image(image_path)
        
        if self.transform:
            if self.is_training:
                # ëŒ€ì¡° í•™ìŠµì„ ìœ„í•´ ë‘ ê°œì˜ ë‹¤ë¥¸ ì¦ê°•ì„ ì ìš©
                image1 = self.transform(image)
                image2 = self.transform(image)
                return (image1, image2), label
            else:
                return self.transform(image), label
            
        return image, label

# ë°ì´í„° ë¡œë” ìƒì„± í•¨ìˆ˜ (ìµœì í™”ëœ ë²„ì „)
def create_data_loaders(config, train_samples_per_class=50):  # 50ìœ¼ë¡œ ì œí•œ
    """ë°ì´í„°ì…‹ì„ í•œ ë²ˆë§Œ ìŠ¤ìº”í•˜ê³  train/val ë¡œë”ë¥¼ ìƒì„±í•˜ì—¬ ìµœì í™”"""
    start_time = time.time()
    print("[LOG] ë°ì´í„° ë¡œë” ìƒì„± ì‹œì‘...")
    
    print("[LOG] ë°ì´í„°ì…‹ ìŠ¤ìº” ì¤‘...")
    scan_start = time.time()
    image_paths = []
    labels = []
    
    # ê° í´ë˜ìŠ¤ë³„ë¡œ ëª¨ë“  ì´ë¯¸ì§€ ê²½ë¡œì™€ ë¼ë²¨ ìˆ˜ì§‘ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    for class_id in range(1, config.num_classes + 1):
        class_dir = os.path.join(config.dataset_dir, str(class_id))
        if os.path.exists(class_dir):
            class_images = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            image_paths.extend(class_images)
            labels.extend([class_id - 1] * len(class_images))
    scan_end = time.time()
    print(f"[LOG] ë°ì´í„°ì…‹ ìŠ¤ìº” ì™„ë£Œ. ì†Œìš” ì‹œê°„: {scan_end - scan_start:.2f}ì´ˆ")

    print(f"ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {len(image_paths)}")
    print(f"í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜: {[labels.count(i) for i in range(config.num_classes)]}")
    
    # Train/validation ë¶„í•  (ì „ì²´ ë°ì´í„° ëŒ€ìƒ)
    split_start = time.time()
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        image_paths, labels, 
        test_size=0.2,  # 20%ë¥¼ validationìœ¼ë¡œ ì‚¬ìš© (ë” ë§ì€ í•™ìŠµ ë°ì´í„°)
        stratify=labels, 
        random_state=42
    )
    split_end = time.time()
    print(f"[LOG] Train/Validation ë¶„í•  ì™„ë£Œ. ì†Œìš” ì‹œê°„: {split_end - split_start:.2f}ì´ˆ")

    
    # Training ë°ì´í„°ëŠ” ê° í´ë˜ìŠ¤ë³„ë¡œ ì œí•œëœ ìƒ˜í”Œë§Œ ì‚¬ìš© (í•„ìš”ì‹œ)
    if train_samples_per_class is not None:
        limit_start = time.time()
        limited_train_paths = []
        limited_train_labels = []
        for class_id in range(config.num_classes):
            class_indices = [i for i, label in enumerate(train_labels) if label == class_id]
            class_paths_for_label = [train_paths[i] for i in class_indices]
            
            if len(class_paths_for_label) > train_samples_per_class:
                selected_paths = random.sample(class_paths_for_label, train_samples_per_class)
            else:
                selected_paths = class_paths_for_label
                print(f"Warning: Class {class_id} has only {len(selected_paths)} training images")
            
            limited_train_paths.extend(selected_paths)
            limited_train_labels.extend([class_id] * len(selected_paths))
        
        train_paths, train_labels = limited_train_paths, limited_train_labels
        limit_end = time.time()
        print(f"[LOG] í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§ ì™„ë£Œ. ì†Œìš” ì‹œê°„: {limit_end - limit_start:.2f}ì´ˆ")


    print(f"í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(train_paths)}")
    print(f"ê²€ì¦ ìƒ˜í”Œ ìˆ˜: {len(val_paths)}")
    print(f"í´ë˜ìŠ¤ë³„ í•™ìŠµ ì´ë¯¸ì§€ ìˆ˜: {[train_labels.count(i) for i in range(config.num_classes)]}")
    print(f"í´ë˜ìŠ¤ë³„ ê²€ì¦ ì´ë¯¸ì§€ ìˆ˜: {[val_labels.count(i) for i in range(config.num_classes)]}")
    

    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(config.image_size, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),  # íšŒì „ ê°ë„ ì¦ê°€
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # ë” ê°•í•œ ìƒ‰ìƒ ë³€í™”
        # RandomGrayscale ì œê±° - ê³ ì–‘ì´ í’ˆì¢… êµ¬ë¶„ì— ìƒ‰ìƒ ì •ë³´ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((config.image_size, config.image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # ë°ì´í„°ì…‹ ìƒì„± (ìºì‹± ë¹„í™œì„±í™”)
    dataset_start = time.time()
    train_dataset = CatDataset(train_paths, train_labels, train_transform, is_training=True)
    val_dataset = CatDataset(val_paths, val_labels, val_transform, is_training=False)
    dataset_end = time.time()
    print(f"[LOG] Dataset ê°ì²´ ìƒì„± ì™„ë£Œ. ì†Œìš” ì‹œê°„: {dataset_end - dataset_start:.2f}ì´ˆ")

    
    # ë°ì´í„° ë¡œë” ìƒì„± (ì†ë„ ìµœì í™”)
    loader_start = time.time()
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config.batch_size, 
        shuffle=True, 
        num_workers=0,  # Windowsì—ì„œ ë” ì•ˆì •ì 
        pin_memory=False,  # CPU ì‚¬ìš©ì‹œ ë¹„í™œì„±í™”
        persistent_workers=False,  # num_workers=0ì´ë¯€ë¡œ ë¹„í™œì„±í™”
        drop_last=False
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config.val_batch_size, # validationìš© ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
        shuffle=False, 
        num_workers=0,  # Windowsì—ì„œ ë” ì•ˆì •ì 
        pin_memory=False,  # CPU ì‚¬ìš©ì‹œ ë¹„í™œì„±í™”
        persistent_workers=False,  # num_workers=0ì´ë¯€ë¡œ ë¹„í™œì„±í™”
        drop_last=False
    )
    loader_end = time.time()
    print(f"[LOG] DataLoader ê°ì²´ ìƒì„± ì™„ë£Œ. ì†Œìš” ì‹œê°„: {loader_end - loader_start:.2f}ì´ˆ")
    
    end_time = time.time()
    print(f"[LOG] ì „ì²´ ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ. ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    
    return train_loader, val_loader, len(train_dataset), len(val_dataset)

def train_epoch(model, train_loader, criterion, optimizer, config, epoch):
    """í•œ ì—í¬í¬ í•™ìŠµ - Rich ì ìš©"""
    model.train()
    
    losses = AverageMeter()
    top1 = AverageMeter()
    contrastive_losses = AverageMeter()  # arc_lossesë¥¼ contrastive_lossesë¡œ ë³€ê²½
    
    # Rich progress bar
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        TimeRemainingColumn(),
        console=console
    ) as progress:
        task = progress.add_task("Training", total=len(train_loader))
        
        for batch_idx, ((images1, images2), labels) in enumerate(train_loader):
            images1 = images1.to(config.device, non_blocking=True)
            images2 = images2.to(config.device, non_blocking=True)
            labels = labels.to(config.device, non_blocking=True)
            
            # Forward pass for both augmentations
            logits1, features1 = model(images1)
            logits2, features2 = model(images2)
            
            # Contrastive learningì„ ìœ„í•œ íŠ¹ì§• ê²°í•©
            features = torch.stack([features1, features2], dim=1)  # [batch_size, 2, feature_dim]
            
            # Loss ê³„ì‚°
            ce_loss = (criterion(logits1, labels) + criterion(logits2, labels)) / 2
            
            # Contrastive loss (NT-Xent) - arc_margin_loss ëŒ€ì‹  nt_xent_loss ì‚¬ìš©
            contrastive_loss_val = nt_xent_loss(
                features, labels, config.temperature
            )
            
            # ì „ì²´ loss
            total_loss = ce_loss + 0.1 * contrastive_loss_val
            
            # Backward pass
            optimizer.zero_grad()
            total_loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            prec1 = (accuracy(logits1, labels, topk=(1,))[0] + accuracy(logits2, labels, topk=(1,))[0]) / 2
            losses.update(total_loss.item(), images1.size(0))
            top1.update(prec1.item(), images1.size(0))
            contrastive_losses.update(contrastive_loss_val.item(), images1.size(0))  # arc_lossesë¥¼ contrastive_lossesë¡œ ë³€ê²½
            
            # Progress ì—…ë°ì´íŠ¸
            progress.update(task, advance=1)
            
            # Description ì—…ë°ì´íŠ¸ - Arcë¥¼ Contrastiveë¡œ ë³€ê²½
            progress.update(task, description=f"Epoch {epoch+1} | Loss: {losses.avg:.4f} | Acc: {top1.avg:.2f}% | Contrastive: {contrastive_losses.avg:.4f}")
    
    return losses.avg, top1.avg

def validate(model, val_loader, criterion, config):
    """ê²€ì¦ - Rich ì ìš©"""
    model.eval()
    
    losses = AverageMeter()
    top1 = AverageMeter()
    
    # Rich progress bar
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        TimeRemainingColumn(),
        console=console
    ) as progress:
        task = progress.add_task("Validation", total=len(val_loader))
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(val_loader):
                images = images.to(config.device, non_blocking=True)
                labels = labels.to(config.device, non_blocking=True)
                
                # Forward pass
                logits, _ = model(images)
                
                # Loss ê³„ì‚°
                loss = criterion(logits, labels)
                
                # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                prec1 = accuracy(logits, labels, topk=(1,))[0]
                losses.update(loss.item(), images.size(0))
                top1.update(prec1.item(), images.size(0))
                
                # Progress ì—…ë°ì´íŠ¸
                progress.update(task, advance=1)
                progress.update(task, description=f"Validation | Loss: {losses.avg:.4f} | Acc: {top1.avg:.2f}%")
    
    return losses.avg, top1.avg

def extract_features(model, data_loader, config):
    """ëª¨ë¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ - ìµœì í™”ëœ ë²„ì „ (GPU-CPU ì „ì†¡ ìµœì í™”)"""
    model.eval()
    features_list = []
    labels_list = []
    
    total_batches = len(data_loader)
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(data_loader):
            # ë°°ì¹˜ êµ¬ì¡°ì— ë”°ë¥¸ ì²˜ë¦¬ (ë‹¨ìˆœí™”)
            try:
                if isinstance(batch, tuple) and len(batch) == 2:
                    first_item = batch[0]
                    labels = batch[1]
                    
                    # ì²« ë²ˆì§¸ ì•„ì´í…œì´ íŠœí”Œì¸ ê²½ìš° (paired augmentations)
                    if isinstance(first_item, tuple):
                        images1, images2 = first_item
                        images = images1.to(config.device, non_blocking=True)  # ì²« ë²ˆì§¸ augmentationë§Œ ì‚¬ìš©
                    else:
                        # ì¼ë°˜ì ì¸ ê²½ìš°
                        images = first_item.to(config.device, non_blocking=True)
                    
                    labels = labels.to(config.device, non_blocking=True)
                    
                elif isinstance(batch, list) and len(batch) == 2:
                    first_item = batch[0]
                    labels = batch[1]
                    
                    # ì²« ë²ˆì§¸ ì•„ì´í…œì´ íŠœí”Œì¸ ê²½ìš° (paired augmentations)
                    if isinstance(first_item, tuple):
                        images1, images2 = first_item
                        images = images1.to(config.device, non_blocking=True)  # ì²« ë²ˆì§¸ augmentationë§Œ ì‚¬ìš©
                    else:
                        # ì¼ë°˜ì ì¸ ê²½ìš°
                        images = first_item.to(config.device, non_blocking=True)
                    
                    labels = labels.to(config.device, non_blocking=True)
                
                else:
                    print(f"Unexpected batch structure: {type(batch)}")
                    continue
                
                # íŠ¹ì§• ì¶”ì¶œ
                features = model(images, return_features=True)
                
                # GPUì—ì„œ CPUë¡œ ì „ì†¡ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                features_list.append(features)
                labels_list.append(labels)
                
                # ê°„ë‹¨í•œ ì§„í–‰ í‘œì‹œ (ë§¤ 30ë²ˆì§¸ ë°°ì¹˜ë§ˆë‹¤, ë” ë§ì€ ìƒ˜í”Œì´ë¯€ë¡œ)
                if (batch_idx + 1) % 30 == 0 or (batch_idx + 1) == total_batches:
                    processed_samples = batch_idx * config.val_batch_size + images.size(0)
                    print(f'Feature extraction: [{batch_idx + 1}/{total_batches}] '
                          f'Processed: {processed_samples} samples')
                
            except Exception as e:
                print(f"Error processing batch {batch_idx}: {e}")
                continue
    
    if not features_list:
        raise ValueError("No features were extracted. Check the data loader structure.")
    
    # ëª¨ë“  íŠ¹ì§•ì„ í•œ ë²ˆì— CPUë¡œ ì „ì†¡ (ìµœì í™”)
    print("GPUì—ì„œ CPUë¡œ íŠ¹ì§• ì „ì†¡ ì¤‘...")
    all_features = torch.cat(features_list, dim=0).cpu().numpy()
    all_labels = torch.cat(labels_list, dim=0).cpu().numpy()
    
    return all_features, all_labels

# ì¶”ê°€ import ìˆ˜ì • (UMAP ì œê±°)
from sklearn.decomposition import PCA
# import umap.umap_ as umap  # UMAP ì œê±°

def visualize_tsne(features, labels, class_names, save_path):
    """t-SNEë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì  ì‹œê°í™”"""
    print("t-SNE ì°¨ì› ì¶•ì†Œ ì¤‘...")
    
    # t-SNE ì ìš©
    tsne = TSNE(n_components=2, random_state=42, perplexity=30)
    features_2d = tsne.fit_transform(features)
    
    # ì‹œê°í™”
    plt.figure(figsize=(12, 10))
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì •
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']  # ë¹¨ê°•, ì²­ë¡, íŒŒë‘
    markers = ['o', 's', '^']  # ì›, ì‚¬ê°í˜•, ì‚¼ê°í˜•
    
    for i, class_name in enumerate(class_names):
        mask = labels == i
        plt.scatter(
            features_2d[mask, 0], 
            features_2d[mask, 1], 
            c=colors[i], 
            marker=markers[i],
            s=100, 
            alpha=0.7, 
            label=f'Class {i+1}: {class_name}',
            edgecolors='black',
            linewidth=0.5
        )
    
    plt.title('t-SNE Visualization of Cat Features (ResNet50 + Contrastive Learning)', fontsize=16, fontweight='bold')
    plt.xlabel('t-SNE Component 1', fontsize=12)
    plt.ylabel('t-SNE Component 2', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # ì¶• ë ˆì´ë¸” ì œê±°
    plt.xticks([])
    plt.yticks([])
    
    # ì €ì¥
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"t-SNE ì‹œê°í™”ê°€ {save_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def visualize_pca(features, labels, class_names, save_path):
    """PCAë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì  ì‹œê°í™”"""
    console.print("ğŸ”„ Applying PCA dimensionality reduction...")
    
    # PCA ì ìš©
    pca = PCA(n_components=2, random_state=42)
    features_2d = pca.fit_transform(features)
    
    # ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨ ê³„ì‚°
    explained_variance_ratio = pca.explained_variance_ratio_
    total_variance = sum(explained_variance_ratio)
    
    # ì‹œê°í™”
    plt.figure(figsize=(12, 10))
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    markers = ['o', 's', '^']
    
    for i, class_name in enumerate(class_names):
        mask = labels == i
        plt.scatter(
            features_2d[mask, 0], 
            features_2d[mask, 1], 
            c=colors[i], 
            marker=markers[i],
            s=100, 
            alpha=0.7, 
            label=f'Class {i+1}: {class_name}',
            edgecolors='black',
            linewidth=0.5
        )
    
    plt.title(f'PCA Visualization of Cat Features (ResNet50 + Contrastive Learning)\n(Explained Variance: {total_variance:.1%})', 
              fontsize=16, fontweight='bold')
    plt.xlabel(f'PC1 ({explained_variance_ratio[0]:.1%})', fontsize=12)
    plt.ylabel(f'PC2 ({explained_variance_ratio[1]:.1%})', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    console.print(f"âœ… PCA visualization saved to: {save_path}")

def visualize_umap(features, labels, class_names, save_path):
    """UMAPì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì  ì‹œê°í™”"""
    try:
        import umap
        print("UMAP ì°¨ì› ì¶•ì†Œ ì¤‘...")
        
        # UMAP ì ìš©
        reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)
        features_2d = reducer.fit_transform(features)
        
        # ì‹œê°í™”
        plt.figure(figsize=(12, 10))
        
        # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì •
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']  # ë¹¨ê°•, ì²­ë¡, íŒŒë‘
        markers = ['o', 's', '^']  # ì›, ì‚¬ê°í˜•, ì‚¼ê°í˜•
        
        for i, class_name in enumerate(class_names):
            mask = labels == i
            plt.scatter(
                features_2d[mask, 0], 
                features_2d[mask, 1], 
                c=colors[i], 
                marker=markers[i],
                s=100, 
                alpha=0.7, 
                label=f'Class {i+1}: {class_name}',
                edgecolors='black',
                linewidth=0.5
            )
        
        plt.title('UMAP Visualization of Cat Features (Pretrained ResNet50 + Contrastive Learning)', fontsize=16, fontweight='bold')
        plt.xlabel('UMAP Component 1', fontsize=12)
        plt.ylabel('UMAP Component 2', fontsize=12)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # ì¶• ë ˆì´ë¸” ì œê±°
        plt.xticks([])
        plt.yticks([])
        
        # ì €ì¥
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"UMAP ì‹œê°í™”ê°€ {save_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return save_path
        
    except ImportError:
        print("UMAP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. UMAP ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

def create_visualization_comparison(features, labels, class_names, save_dir):
    """ì—¬ëŸ¬ ì‹œê°í™” ë°©ë²•ìœ¼ë¡œ ë¹„êµ"""
    print("ì—¬ëŸ¬ ì‹œê°í™” ë°©ë²•ìœ¼ë¡œ íŠ¹ì§• ë¹„êµ ì¤‘...")
    
    # t-SNE ì‹œê°í™”
    tsne_path = os.path.join(save_dir, 'tsne_visualization_resnet50_contrastive.png')
    visualize_tsne(features, labels, class_names, tsne_path)
    
    # PCA ì‹œê°í™”
    pca_path = os.path.join(save_dir, 'pca_visualization_resnet50_contrastive.png')
    visualize_pca(features, labels, class_names, pca_path)
    
    return tsne_path, pca_path, None  # umap_path ëŒ€ì‹  None ë°˜í™˜

def create_summary_table(config, train_size, val_size):
    """ì„¤ì • ìš”ì•½ í…Œì´ë¸” ìƒì„±"""
    table = Table(title="Training Configuration", box=box.ROUNDED)
    
    table.add_column("Parameter", style="cyan", no_wrap=True)
    table.add_column("Value", style="magenta")
    
    table.add_row("Backbone", config.backbone_name)
    table.add_row("Learning Rate", f"{config.learning_rate:.1e}")
    table.add_row("Batch Size", str(config.batch_size))
    table.add_row("Epochs", str(config.num_epochs))
    table.add_row("Temperature", str(config.temperature))
    table.add_row("Training Samples", str(train_size))
    table.add_row("Validation Samples", str(val_size))
    table.add_row("Device", str(config.device))
    
    return table

def create_epoch_table(epoch, train_loss, train_acc, val_loss, val_acc, best_acc, lr):
    """ì—í¬í¬ ê²°ê³¼ í…Œì´ë¸” ìƒì„±"""
    table = Table(title=f"Epoch {epoch} Results", box=box.ROUNDED)
    
    table.add_column("Metric", style="cyan", no_wrap=True)
    table.add_column("Value", style="magenta")
    
    table.add_row("Train Loss", f"{train_loss:.4f}")
    table.add_row("Train Accuracy", f"{train_acc:.2f}%")
    table.add_row("Val Loss", f"{val_loss:.4f}")
    table.add_row("Val Accuracy", f"{val_acc:.2f}%")
    table.add_row("Best Accuracy", f"{best_acc:.2f}%")
    table.add_row("Learning Rate", f"{lr:.6f}")
    
    return table

def main():
    main_start_time = time.time()
    
    # Rich ì‹œì‘ ë©”ì‹œì§€
    console.print(Panel.fit(
        "[bold blue]ResNet50 + Contrastive Learning Training[/bold blue]\n"
        f"[dim]Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}[/dim]",
        border_style="blue"
    ))
    
    config = Config()
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, train_size, val_size = create_data_loaders(config, train_samples_per_class=200)
    
    # ì„¤ì • ìš”ì•½ í…Œì´ë¸” ì¶œë ¥
    summary_table = create_summary_table(config, train_size, val_size)
    console.print(summary_table)
    
    # ëª¨ë¸ ìƒì„±
    with console.status("[bold green]Loading model...") as status:
        model = CatDiscriminationModel(config).to(config.device)
        status.update("[bold green]Model loaded successfully!")
    
    console.print(f"[green]âœ“[/green] Model loaded: {config.backbone_name}")

    # ì˜µí‹°ë§ˆì´ì € ë‹¨ì¼í™” - origin_train.pyì™€ ë™ì¼í•˜ê²Œ ëª¨ë“  íŒŒë¼ë¯¸í„°ì— ë™ì¼í•œ í•™ìŠµë¥  ì ìš©
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=config.learning_rate,  # ëª¨ë“  íŒŒë¼ë¯¸í„°ì— ë™ì¼í•œ í•™ìŠµë¥  ì ìš©
        weight_decay=config.weight_decay
    )
    
    # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì •ë³´ ì¶œë ¥
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    backbone_params = sum(p.numel() for p in model.backbone.parameters())
    projection_params = sum(p.numel() for p in model.projection_head.parameters())
    classifier_params = sum(p.numel() for p in model.classifier.parameters())
    
    console.print(f"[INFO] ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")
    console.print(f"[INFO] í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {trainable_params:,}")
    console.print(f"[INFO] ë°±ë³¸ íŒŒë¼ë¯¸í„° ìˆ˜: {backbone_params:,} (í•™ìŠµë¥ : {config.learning_rate:.1e})")
    console.print(f"[INFO] Projection head íŒŒë¼ë¯¸í„° ìˆ˜: {projection_params:,} (í•™ìŠµë¥ : {config.learning_rate:.1e})")
    console.print(f"[INFO] Classifier íŒŒë¼ë¯¸í„° ìˆ˜: {classifier_params:,} (í•™ìŠµë¥ : {config.learning_rate:.1e})")
    console.print(f"[INFO] ë°±ë³¸ freeze ìƒíƒœ: False (ì „ì²´ ëª¨ë¸ í•™ìŠµ, ë‹¨ì¼ í•™ìŠµë¥ )")
    
    # Loss function
    criterion = nn.CrossEntropyLoss()
    
    # Learning rate scheduler - CosineAnnealingLRë¡œ ë³€ê²½
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=config.num_epochs, eta_min=1e-6
    )
    
    # í•™ìŠµ ë£¨í”„
    best_acc = 0.0
    patience_counter = 0
    patience = 5
    validation_interval = 3  # 3 ì—í¬í¬ë§ˆë‹¤ validation
    
    console.print(Panel.fit(
        f"[bold yellow]Training Configuration[/bold yellow]\n"
        f"Total Epochs: {config.num_epochs}\n"
        f"Validation Interval: Every {validation_interval} epochs\n"
        f"Early Stopping Patience: {patience}\n"
        f"Scheduler: CosineAnnealingLR (T_max={config.num_epochs}, eta_min=1e-6)",
        border_style="yellow"
    ))
    
    # ì „ì²´ í•™ìŠµ ì§„í–‰ë¥ ì„ ìœ„í•œ Rich progress
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        TimeRemainingColumn(),
        console=console
    ) as progress:
        epoch_task = progress.add_task("Training Progress", total=config.num_epochs)
        
        for epoch in range(config.num_epochs):
            epoch_start_time = time.time()
            
            # í•™ìŠµ
            train_loss, train_acc = train_epoch(
                model, train_loader, criterion, optimizer, config, epoch
            )
            
            # Validation ê°„ê²© ì¡°ì ˆ
            if (epoch + 1) % validation_interval == 0 or epoch == 0:
                val_loss, val_acc = validate(model, val_loader, criterion, config)
                
                # Learning rate ì—…ë°ì´íŠ¸ - CosineAnnealingLRëŠ” ë§¤ ì—í¬í¬ë§ˆë‹¤ í˜¸ì¶œ
                old_lr = optimizer.param_groups[0]['lr']
                scheduler.step()  # ë§¤ ì—í¬í¬ë§ˆë‹¤ í˜¸ì¶œ
                new_lr = optimizer.param_groups[0]['lr']
                
                if new_lr != old_lr:
                    console.print(f"[yellow]âš [/yellow] Learning rate changed from {old_lr:.6f} to {new_lr:.6f}")
                
                # ì—í¬í¬ ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥
                epoch_table = create_epoch_table(epoch+1, train_loss, train_acc, val_loss, val_acc, best_acc, new_lr)
                console.print(epoch_table)
                
                # ëª¨ë¸ ì €ì¥
                if val_acc > best_acc:
                    best_acc = val_acc
                    patience_counter = 0
                    save_checkpoint(
                        model, optimizer, epoch, val_acc,
                        os.path.join(config.save_dir, 'best_model_resnet50_contrastive.pth')
                    )
                    console.print(f"[green]âœ“[/green] New best model saved! Accuracy: {best_acc:.2f}%")
                else:
                    patience_counter += 1
                    console.print(f"[red]âœ—[/red] No improvement for {patience_counter} epochs")
                
                # Early stopping
                if patience_counter >= patience:
                    console.print(f"[red]âš [/red] Early stopping triggered after {epoch+1} epochs")
                    break
            else:
                # Validationì„ í•˜ì§€ ì•ŠëŠ” ì—í¬í¬ì—ì„œë„ ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
                old_lr = optimizer.param_groups[0]['lr']
                scheduler.step()  # ë§¤ ì—í¬í¬ë§ˆë‹¤ í˜¸ì¶œ
                new_lr = optimizer.param_groups[0]['lr']
                
                # Validationì„ í•˜ì§€ ì•ŠëŠ” ì—í¬í¬
                console.print(f"[dim]Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%[/dim]")
                console.print(f"[dim]Validation: Skipped (next validation at epoch {epoch + validation_interval})[/dim]")
                console.print(f"[dim]Learning Rate: {new_lr:.6f}[/dim]")
            
            # ì „ì²´ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress.update(epoch_task, advance=1)
            progress.update(epoch_task, description=f"Training | Best Val Acc: {best_acc:.2f}%")
            
            epoch_end_time = time.time()
            console.print(f"[dim]Epoch {epoch+1} completed in {epoch_end_time - epoch_start_time:.2f}s[/dim]")

    
    # í•™ìŠµ ì™„ë£Œ ë©”ì‹œì§€
    console.print(Panel.fit(
        f"[bold green]Training Completed![/bold green]\n"
        f"Best Accuracy: {best_acc:.2f}%\n"
        f"Total Time: {time.time() - main_start_time:.2f}s",
        border_style="green"
    ))
    
    # íŠ¹ì§• ì¶”ì¶œ
    console.print(Panel.fit(
        "[bold blue]Feature Extraction[/bold blue]",
        border_style="blue"
    ))
    
    with console.status("[bold green]Extracting features...") as status:
        val_features, val_labels = extract_features(model, val_loader, config)
        status.update("[bold green]Feature extraction completed!")

    console.print(f"[green]âœ“[/green] Total features: {len(val_features)}")
    console.print(f"[green]âœ“[/green] Feature dimension: {val_features.shape[1]}")
    console.print(f"[green]âœ“[/green] Class distribution: {[np.sum(val_labels == i) for i in range(config.num_classes)]}")
    
    # í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜
    class_names = ['Class 1', 'Class 2', 'Class 3']
    
    # ì—¬ëŸ¬ ì‹œê°í™” ë°©ë²•ìœ¼ë¡œ ë¹„êµ
    tsne_path, pca_path, umap_path = create_visualization_comparison(
        val_features, val_labels, class_names, config.save_dir
    )

    # íŠ¹ì§• í†µê³„ ì •ë³´ ì €ì¥
    with console.status("[bold green]Saving feature statistics...") as status:
        stats_save_path = os.path.join(config.save_dir, 'feature_stats_resnet50_contrastive.txt')
        with open(stats_save_path, 'w', encoding='utf-8') as f:
            f.write(f"=== ResNet50 + Contrastive Learning í•™ìŠµ í›„ íŠ¹ì§• ë¶„ì„ ê²°ê³¼ ===\n")
            f.write(f"ë°±ë³¸ ëª¨ë¸: {config.backbone_name}\n")
            f.write(f"í•™ìŠµ ë°©ì‹: ì „ì²´ ëª¨ë¸ í•™ìŠµ (ë‹¨ì¼ í•™ìŠµë¥ ) + Contrastive Learning\n")
            f.write(f"Temperature: {config.temperature}\n")
            f.write(f"Projection Dimension: {config.projection_dim}\n")
            f.write(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(val_features)}\n")
            f.write(f"íŠ¹ì§• ì°¨ì›: {val_features.shape[1]}\n")
            f.write(f"í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\n")
            for i in range(config.num_classes):
                f.write(f"  Class {i+1}: {np.sum(val_labels == i)}ê°œ\n")
            f.write(f"\níŠ¹ì§• í†µê³„:\n")
            f.write(f"  í‰ê· : {np.mean(val_features):.4f}\n")
            f.write(f"  í‘œì¤€í¸ì°¨: {np.std(val_features):.4f}\n")
            f.write(f"  ìµœì†Œê°’: {np.min(val_features):.4f}\n")
            f.write(f"  ìµœëŒ€ê°’: {np.max(val_features):.4f}\n")
            f.write(f"\nì‹œê°í™” íŒŒì¼:\n")
            f.write(f"  t-SNE: {tsne_path}\n")
            f.write(f"  PCA: {pca_path}\n")
            if umap_path:
                f.write(f"  UMAP: {umap_path}\n")
        status.update("[bold green]Feature statistics saved!")

    console.print(f"[green]âœ“[/green] Feature statistics saved to: {stats_save_path}")
    console.print(f"[green]âœ“[/green] Visualizations saved:")
    console.print(f"  â€¢ t-SNE: {tsne_path}")
    console.print(f"  â€¢ PCA: {pca_path}")
    if umap_path:
        console.print(f"  â€¢ UMAP: {umap_path}")
    
    # ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€
    console.print(Panel.fit(
        f"[bold green]All tasks completed successfully![/bold green]\n"
        f"Total execution time: {time.time() - main_start_time:.2f}s",
        border_style="green"
    ))


if __name__ == "__main__":
    main()
